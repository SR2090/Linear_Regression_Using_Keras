{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LRKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8FwJVbTk7zXhXXMozAtym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SR2090/Linear_Regression_Using_Keras/blob/main/LRKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FrsHcKdNuwn"
      },
      "source": [
        "# The purpose of the training "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3XdfOOYVt0Q"
      },
      "source": [
        "- Understanding how to build models using keras\n",
        "- Implementing Linear Regression\n",
        "\n",
        "What is Linear Regression ?\n",
        "Linear Regression is a linear relationship model between two variables x and y where x is an independent variable, y is the dependent variable.\n",
        "X is normally referred to as the Sample\n",
        "Y is reffered to as Target\n",
        "We want to find a straight line that will fit the model in a way that the mean square error distance from each of those points to the line is a minimum. \n",
        "Once such a line is acheived we can predict corresponding y variable to each x using that line\n",
        "\n",
        "\"We want to find the slope of the line with the least error. Once, we are able to model the given data points, we can predict the value on y axis, for a new point on x axis.\"\n",
        "\n",
        "The purpose of the training is to predict house prices. This is done by finding the weights (w0 to w12) and the biases for which the network produces the correct output\n",
        "\n",
        "Result:\n",
        "- The network will be trained if the error between the predicted output and the ground truth becomes very low and doesn't decrease any further.\n",
        "- About the dataset\n",
        "  - https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "\n",
        "Process:\n",
        "- Use Sequentail class to create a Sequential Model from which we craete the Network Graph\n",
        "- A dense layer is for the number of input is equal to the number of features in the data set(13) and get a single output (price)\n",
        "- --------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nGvfw3fYbdF",
        "outputId": "84286b87-a7a2-4de1-f5c7-13c71fa68003",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "# Sample points\n",
        "(X_train, Y_train) , (X_test, Y_test) = boston_housing.load_data()\n",
        "\n",
        "print(\"Training set size: \", X_train.shape)\n",
        "print(\"Test set size: \", X_test.shape)\n",
        "print(\"Training example features: \", X_train[0,:])\n",
        "print(\"Training example output: \", Y_train[0])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "Training set size:  (404, 13)\n",
            "Test set size:  (102, 13)\n",
            "Training example features:  [  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
            "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
            "Training example output:  15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrjlW1u7Zj_2"
      },
      "source": [
        "# The 13 features \n",
        "nfeatures = X_train.shape[1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GAdnhb1Z0iR",
        "outputId": "6ee1671c-4cb6-419f-dbe5-1ce974b971e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nfeatures"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR-AA8BVbtZD"
      },
      "source": [
        " Here we will create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB1CMTrGZ2ip"
      },
      "source": [
        "# Initiate the model class type here sequential\n",
        "model = Sequential()\n",
        "# First Hiddent Layer\n",
        "model.add(Dense(1, input_shape=(nfeatures,), activation='linear'))\n",
        "# Compiling the parameters \n",
        "# Loss is mean squared error as it is a regression problem\n",
        "# Optimizer \n",
        "# Controls how the network weights, biases or parameters are updated\n",
        "# Loss\n",
        "# How to penalize the network\n",
        "# Metric\n",
        "# The metrics that we want to evaluate during training and testing\n",
        "model.compile(optimizer='rmsprop', loss = 'mse', metrics = ['mse', 'mae'])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4eRTPnta10A",
        "outputId": "76c5700d-e8f9-443b-a91c-da9436200ee5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELbq7pZzbVsb",
        "outputId": "94c4930c-07c1-405b-d9ba-e0d5d60805ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 14 parameters ?\n",
        "# 13 for weights \n",
        "# 1 for bias\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etcc77czbw-k"
      },
      "source": [
        "Here we will train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56l9S1q_bY28",
        "outputId": "74bddea7-2811-4eb3-bd2f-747e65b3a90d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To see detail output, change verbose to True\n",
        "# Here we will train the data\n",
        "model.fit(X_train, Y_train, batch_size=6, epochs=500, verbose=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6596 - mse: 25.6596 - mae: 3.5160\n",
            "Epoch 2/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9639 - mse: 25.9639 - mae: 3.5103\n",
            "Epoch 3/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9545 - mse: 25.9545 - mae: 3.5582\n",
            "Epoch 4/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9107 - mse: 25.9107 - mae: 3.4540\n",
            "Epoch 5/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7603 - mse: 25.7603 - mae: 3.5366\n",
            "Epoch 6/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9142 - mse: 25.9142 - mae: 3.4553\n",
            "Epoch 7/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.2929 - mse: 25.2929 - mae: 3.4807\n",
            "Epoch 8/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5961 - mse: 25.5961 - mae: 3.4855\n",
            "Epoch 9/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9065 - mse: 25.9065 - mae: 3.5425\n",
            "Epoch 10/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0338 - mse: 26.0338 - mae: 3.5811\n",
            "Epoch 11/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1094 - mse: 26.1094 - mae: 3.5288\n",
            "Epoch 12/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8678 - mse: 25.8678 - mae: 3.4840\n",
            "Epoch 13/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7608 - mse: 25.7608 - mae: 3.4828\n",
            "Epoch 14/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1325 - mse: 26.1325 - mae: 3.5099\n",
            "Epoch 15/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9322 - mse: 25.9322 - mae: 3.4661\n",
            "Epoch 16/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5958 - mse: 25.5958 - mae: 3.4756\n",
            "Epoch 17/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5455 - mse: 25.5455 - mae: 3.4048\n",
            "Epoch 18/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3771 - mse: 26.3771 - mae: 3.4935\n",
            "Epoch 19/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.2458 - mse: 26.2458 - mae: 3.5473\n",
            "Epoch 20/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1178 - mse: 25.1178 - mae: 3.4763\n",
            "Epoch 21/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7820 - mse: 25.7820 - mae: 3.4742\n",
            "Epoch 22/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.9403 - mse: 24.9403 - mae: 3.5121\n",
            "Epoch 23/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7300 - mse: 25.7300 - mae: 3.5049\n",
            "Epoch 24/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1515 - mse: 25.1515 - mae: 3.4723\n",
            "Epoch 25/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8075 - mse: 25.8075 - mae: 3.5045\n",
            "Epoch 26/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.3106 - mse: 26.3106 - mae: 3.4742\n",
            "Epoch 27/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6692 - mse: 25.6692 - mae: 3.4915\n",
            "Epoch 28/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9944 - mse: 25.9944 - mae: 3.4565\n",
            "Epoch 29/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9638 - mse: 25.9638 - mae: 3.5315\n",
            "Epoch 30/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5185 - mse: 25.5185 - mae: 3.4569\n",
            "Epoch 31/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0314 - mse: 26.0314 - mae: 3.4817\n",
            "Epoch 32/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8714 - mse: 25.8714 - mae: 3.4653\n",
            "Epoch 33/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7782 - mse: 25.7782 - mae: 3.5326\n",
            "Epoch 34/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6954 - mse: 25.6954 - mae: 3.5490\n",
            "Epoch 35/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1717 - mse: 26.1717 - mae: 3.5031\n",
            "Epoch 36/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8809 - mse: 25.8809 - mae: 3.4803\n",
            "Epoch 37/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9638 - mse: 25.9638 - mae: 3.4815\n",
            "Epoch 38/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5607 - mse: 25.5607 - mae: 3.4266\n",
            "Epoch 39/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9803 - mse: 25.9803 - mae: 3.5779\n",
            "Epoch 40/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0978 - mse: 26.0978 - mae: 3.5234\n",
            "Epoch 41/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1817 - mse: 26.1817 - mae: 3.5163\n",
            "Epoch 42/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1278 - mse: 25.1278 - mae: 3.4252\n",
            "Epoch 43/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0140 - mse: 26.0140 - mae: 3.4967\n",
            "Epoch 44/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8467 - mse: 25.8467 - mae: 3.4543\n",
            "Epoch 45/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7410 - mse: 25.7410 - mae: 3.5175\n",
            "Epoch 46/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8115 - mse: 25.8115 - mae: 3.4901\n",
            "Epoch 47/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9783 - mse: 25.9783 - mae: 3.5033\n",
            "Epoch 48/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8717 - mse: 25.8717 - mae: 3.5137\n",
            "Epoch 49/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3536 - mse: 26.3536 - mae: 3.5546\n",
            "Epoch 50/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9164 - mse: 25.9164 - mae: 3.4672\n",
            "Epoch 51/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7511 - mse: 25.7511 - mae: 3.4804\n",
            "Epoch 52/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8397 - mse: 25.8397 - mae: 3.4694\n",
            "Epoch 53/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7937 - mse: 25.7937 - mae: 3.4806\n",
            "Epoch 54/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.2053 - mse: 26.2053 - mae: 3.5123\n",
            "Epoch 55/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1529 - mse: 25.1529 - mae: 3.4796\n",
            "Epoch 56/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7694 - mse: 25.7694 - mae: 3.4724\n",
            "Epoch 57/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8392 - mse: 25.8392 - mae: 3.5531\n",
            "Epoch 58/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7313 - mse: 25.7313 - mae: 3.4376\n",
            "Epoch 59/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3731 - mse: 26.3731 - mae: 3.5928\n",
            "Epoch 60/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5160 - mse: 25.5160 - mae: 3.5114\n",
            "Epoch 61/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.0997 - mse: 25.0997 - mae: 3.5385\n",
            "Epoch 62/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1085 - mse: 26.1085 - mae: 3.5296\n",
            "Epoch 63/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1123 - mse: 26.1123 - mae: 3.4672\n",
            "Epoch 64/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7676 - mse: 25.7676 - mae: 3.4537\n",
            "Epoch 65/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9450 - mse: 25.9450 - mae: 3.4697\n",
            "Epoch 66/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1580 - mse: 26.1580 - mae: 3.5150\n",
            "Epoch 67/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9263 - mse: 25.9263 - mae: 3.4693\n",
            "Epoch 68/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6268 - mse: 25.6268 - mae: 3.4420\n",
            "Epoch 69/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0249 - mse: 26.0249 - mae: 3.4833\n",
            "Epoch 70/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0605 - mse: 26.0605 - mae: 3.4796\n",
            "Epoch 71/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5401 - mse: 25.5401 - mae: 3.4669\n",
            "Epoch 72/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6384 - mse: 25.6384 - mae: 3.4508\n",
            "Epoch 73/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7901 - mse: 25.7901 - mae: 3.4900\n",
            "Epoch 74/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6345 - mse: 25.6345 - mae: 3.5444\n",
            "Epoch 75/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6704 - mse: 25.6704 - mae: 3.4845\n",
            "Epoch 76/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9320 - mse: 25.9320 - mae: 3.5070\n",
            "Epoch 77/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9208 - mse: 25.9208 - mae: 3.4758\n",
            "Epoch 78/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7782 - mse: 25.7782 - mae: 3.4891\n",
            "Epoch 79/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1520 - mse: 25.1520 - mae: 3.4856\n",
            "Epoch 80/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8431 - mse: 25.8431 - mae: 3.4324\n",
            "Epoch 81/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9777 - mse: 25.9777 - mae: 3.5268\n",
            "Epoch 82/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4846 - mse: 25.4846 - mae: 3.4910\n",
            "Epoch 83/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8109 - mse: 25.8109 - mae: 3.5240\n",
            "Epoch 84/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1379 - mse: 25.1379 - mae: 3.4896\n",
            "Epoch 85/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7126 - mse: 25.7126 - mae: 3.4529\n",
            "Epoch 86/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3963 - mse: 25.3963 - mae: 3.3935\n",
            "Epoch 87/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6872 - mse: 25.6872 - mae: 3.5804\n",
            "Epoch 88/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5838 - mse: 25.5838 - mae: 3.4713\n",
            "Epoch 89/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9369 - mse: 25.9369 - mae: 3.5227\n",
            "Epoch 90/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9197 - mse: 25.9197 - mae: 3.5569\n",
            "Epoch 91/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8244 - mse: 25.8244 - mae: 3.4610\n",
            "Epoch 92/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6299 - mse: 25.6299 - mae: 3.4744\n",
            "Epoch 93/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7687 - mse: 25.7687 - mae: 3.5159\n",
            "Epoch 94/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6168 - mse: 25.6168 - mae: 3.4482\n",
            "Epoch 95/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9050 - mse: 25.9050 - mae: 3.4452\n",
            "Epoch 96/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1252 - mse: 26.1252 - mae: 3.4938\n",
            "Epoch 97/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7976 - mse: 25.7976 - mae: 3.4848\n",
            "Epoch 98/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7121 - mse: 25.7121 - mae: 3.5222\n",
            "Epoch 99/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4134 - mse: 25.4134 - mae: 3.4735\n",
            "Epoch 100/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.2387 - mse: 26.2387 - mae: 3.4730\n",
            "Epoch 101/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8146 - mse: 25.8146 - mae: 3.4222\n",
            "Epoch 102/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0898 - mse: 26.0897 - mae: 3.5176\n",
            "Epoch 103/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7604 - mse: 25.7604 - mae: 3.4573\n",
            "Epoch 104/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8673 - mse: 25.8673 - mae: 3.5044\n",
            "Epoch 105/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5005 - mse: 25.5005 - mae: 3.5199\n",
            "Epoch 106/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.8470 - mse: 24.8470 - mae: 3.4994\n",
            "Epoch 107/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5676 - mse: 25.5676 - mae: 3.4615\n",
            "Epoch 108/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6089 - mse: 25.6089 - mae: 3.5297\n",
            "Epoch 109/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7710 - mse: 25.7710 - mae: 3.4689\n",
            "Epoch 110/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8297 - mse: 25.8297 - mae: 3.5270\n",
            "Epoch 111/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6507 - mse: 25.6507 - mae: 3.4724\n",
            "Epoch 112/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0515 - mse: 26.0515 - mae: 3.5299\n",
            "Epoch 113/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0070 - mse: 26.0070 - mae: 3.4949\n",
            "Epoch 114/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6305 - mse: 25.6305 - mae: 3.4326\n",
            "Epoch 115/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7663 - mse: 25.7663 - mae: 3.4923\n",
            "Epoch 116/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0598 - mse: 26.0598 - mae: 3.4512\n",
            "Epoch 117/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9872 - mse: 25.9872 - mae: 3.4945\n",
            "Epoch 118/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4631 - mse: 25.4631 - mae: 3.4916\n",
            "Epoch 119/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9129 - mse: 25.9129 - mae: 3.4343\n",
            "Epoch 120/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4525 - mse: 25.4525 - mae: 3.4900\n",
            "Epoch 121/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0121 - mse: 26.0121 - mae: 3.4946\n",
            "Epoch 122/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9925 - mse: 25.9925 - mae: 3.4139\n",
            "Epoch 123/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2461 - mse: 26.2461 - mae: 3.4755\n",
            "Epoch 124/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1203 - mse: 25.1203 - mae: 3.4946\n",
            "Epoch 125/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7156 - mse: 25.7156 - mae: 3.4798\n",
            "Epoch 126/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0907 - mse: 26.0907 - mae: 3.4923\n",
            "Epoch 127/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5334 - mse: 25.5334 - mae: 3.5229\n",
            "Epoch 128/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3301 - mse: 26.3301 - mae: 3.4598\n",
            "Epoch 129/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0950 - mse: 26.0950 - mae: 3.4755\n",
            "Epoch 130/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9808 - mse: 25.9808 - mae: 3.4733\n",
            "Epoch 131/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8099 - mse: 25.8099 - mae: 3.4871\n",
            "Epoch 132/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5393 - mse: 25.5393 - mae: 3.5236\n",
            "Epoch 133/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1058 - mse: 26.1058 - mae: 3.4750\n",
            "Epoch 134/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.5868 - mse: 25.5868 - mae: 3.5168\n",
            "Epoch 135/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5032 - mse: 25.5032 - mae: 3.4788\n",
            "Epoch 136/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1856 - mse: 26.1856 - mae: 3.5327\n",
            "Epoch 137/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9434 - mse: 25.9434 - mae: 3.4969\n",
            "Epoch 138/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9221 - mse: 25.9221 - mae: 3.4975\n",
            "Epoch 139/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3937 - mse: 25.3937 - mae: 3.4738\n",
            "Epoch 140/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2300 - mse: 26.2300 - mae: 3.4861\n",
            "Epoch 141/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6760 - mse: 25.6760 - mae: 3.4681\n",
            "Epoch 142/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8902 - mse: 25.8902 - mae: 3.5022\n",
            "Epoch 143/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8870 - mse: 25.8870 - mae: 3.4903\n",
            "Epoch 144/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7789 - mse: 25.7789 - mae: 3.4498\n",
            "Epoch 145/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1098 - mse: 25.1098 - mae: 3.4577\n",
            "Epoch 146/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8279 - mse: 25.8279 - mae: 3.4864\n",
            "Epoch 147/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1536 - mse: 26.1536 - mae: 3.5089\n",
            "Epoch 148/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3283 - mse: 25.3283 - mae: 3.4379\n",
            "Epoch 149/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6349 - mse: 25.6349 - mae: 3.4510\n",
            "Epoch 150/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.0980 - mse: 25.0980 - mae: 3.4716\n",
            "Epoch 151/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8405 - mse: 25.8405 - mae: 3.5100\n",
            "Epoch 152/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7625 - mse: 25.7625 - mae: 3.5244\n",
            "Epoch 153/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7532 - mse: 25.7532 - mae: 3.4696\n",
            "Epoch 154/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0127 - mse: 26.0127 - mae: 3.5582\n",
            "Epoch 155/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.2652 - mse: 25.2652 - mae: 3.4641\n",
            "Epoch 156/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3326 - mse: 25.3326 - mae: 3.4151\n",
            "Epoch 157/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4611 - mse: 25.4611 - mae: 3.4858\n",
            "Epoch 158/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9203 - mse: 25.9203 - mae: 3.4904\n",
            "Epoch 159/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7725 - mse: 25.7725 - mae: 3.4585\n",
            "Epoch 160/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3947 - mse: 25.3947 - mae: 3.4889\n",
            "Epoch 161/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.0342 - mse: 25.0342 - mae: 3.4837\n",
            "Epoch 162/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6812 - mse: 25.6812 - mae: 3.4766\n",
            "Epoch 163/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7862 - mse: 25.7862 - mae: 3.4982\n",
            "Epoch 164/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5636 - mse: 25.5636 - mae: 3.4517\n",
            "Epoch 165/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.4367 - mse: 25.4367 - mae: 3.5298\n",
            "Epoch 166/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6390 - mse: 25.6390 - mae: 3.4976\n",
            "Epoch 167/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4856 - mse: 25.4856 - mae: 3.4578\n",
            "Epoch 168/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8863 - mse: 25.8863 - mae: 3.5085\n",
            "Epoch 169/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7076 - mse: 25.7076 - mae: 3.4924\n",
            "Epoch 170/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.3931 - mse: 25.3931 - mae: 3.5029\n",
            "Epoch 171/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1214 - mse: 26.1214 - mae: 3.4881\n",
            "Epoch 172/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.4802 - mse: 25.4802 - mae: 3.4507\n",
            "Epoch 173/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1122 - mse: 26.1122 - mae: 3.5115\n",
            "Epoch 174/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1261 - mse: 26.1261 - mae: 3.5099\n",
            "Epoch 175/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0920 - mse: 26.0920 - mae: 3.4641\n",
            "Epoch 176/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7048 - mse: 25.7048 - mae: 3.4794\n",
            "Epoch 177/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0695 - mse: 26.0695 - mae: 3.5334\n",
            "Epoch 178/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6070 - mse: 25.6070 - mae: 3.4420\n",
            "Epoch 179/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.7706 - mse: 25.7706 - mae: 3.5256\n",
            "Epoch 180/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 24.9937 - mse: 24.9937 - mae: 3.4852\n",
            "Epoch 181/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5302 - mse: 25.5302 - mae: 3.5188\n",
            "Epoch 182/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9458 - mse: 25.9458 - mae: 3.4431\n",
            "Epoch 183/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5228 - mse: 25.5228 - mae: 3.5477\n",
            "Epoch 184/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.2350 - mse: 26.2350 - mae: 3.4930\n",
            "Epoch 185/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1208 - mse: 25.1208 - mae: 3.4003\n",
            "Epoch 186/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6547 - mse: 25.6547 - mae: 3.4598\n",
            "Epoch 187/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7630 - mse: 25.7630 - mae: 3.5295\n",
            "Epoch 188/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.3603 - mse: 25.3603 - mae: 3.4872\n",
            "Epoch 189/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6088 - mse: 25.6088 - mae: 3.4725\n",
            "Epoch 190/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0236 - mse: 26.0236 - mae: 3.4849\n",
            "Epoch 191/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7975 - mse: 25.7975 - mae: 3.4849\n",
            "Epoch 192/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4122 - mse: 25.4122 - mae: 3.5220\n",
            "Epoch 193/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5342 - mse: 25.5342 - mae: 3.4651\n",
            "Epoch 194/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8911 - mse: 25.8911 - mae: 3.4823\n",
            "Epoch 195/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.3885 - mse: 25.3885 - mae: 3.4316\n",
            "Epoch 196/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3834 - mse: 25.3834 - mae: 3.5729\n",
            "Epoch 197/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0162 - mse: 26.0162 - mae: 3.4869\n",
            "Epoch 198/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.1348 - mse: 25.1348 - mae: 3.4563\n",
            "Epoch 199/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1259 - mse: 26.1259 - mae: 3.4627\n",
            "Epoch 200/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.5845 - mse: 26.5845 - mae: 3.4918\n",
            "Epoch 201/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8551 - mse: 25.8551 - mae: 3.5440\n",
            "Epoch 202/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6832 - mse: 25.6832 - mae: 3.4296\n",
            "Epoch 203/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2986 - mse: 25.2986 - mae: 3.5289\n",
            "Epoch 204/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7271 - mse: 25.7271 - mae: 3.4801\n",
            "Epoch 205/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2133 - mse: 25.2133 - mae: 3.5134\n",
            "Epoch 206/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2775 - mse: 26.2775 - mae: 3.4787\n",
            "Epoch 207/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0141 - mse: 26.0141 - mae: 3.4998\n",
            "Epoch 208/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8818 - mse: 25.8818 - mae: 3.4761\n",
            "Epoch 209/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7687 - mse: 25.7687 - mae: 3.5436\n",
            "Epoch 210/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9292 - mse: 25.9292 - mae: 3.4750\n",
            "Epoch 211/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3793 - mse: 25.3793 - mae: 3.4388\n",
            "Epoch 212/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9210 - mse: 25.9210 - mae: 3.5016\n",
            "Epoch 213/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0062 - mse: 26.0062 - mae: 3.5358\n",
            "Epoch 214/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2015 - mse: 26.2015 - mae: 3.5269\n",
            "Epoch 215/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9121 - mse: 25.9121 - mae: 3.5690\n",
            "Epoch 216/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8997 - mse: 25.8997 - mae: 3.5010\n",
            "Epoch 217/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3527 - mse: 25.3527 - mae: 3.4561\n",
            "Epoch 218/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6881 - mse: 25.6881 - mae: 3.4650\n",
            "Epoch 219/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9400 - mse: 25.9400 - mae: 3.4703\n",
            "Epoch 220/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8416 - mse: 25.8416 - mae: 3.4635\n",
            "Epoch 221/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7872 - mse: 25.7872 - mae: 3.5041\n",
            "Epoch 222/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2759 - mse: 25.2759 - mae: 3.4545\n",
            "Epoch 223/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8169 - mse: 25.8169 - mae: 3.4711\n",
            "Epoch 224/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7996 - mse: 25.7996 - mae: 3.5186\n",
            "Epoch 225/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0743 - mse: 26.0743 - mae: 3.4888\n",
            "Epoch 226/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9727 - mse: 25.9727 - mae: 3.4968\n",
            "Epoch 227/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.8677 - mse: 25.8677 - mae: 3.4760\n",
            "Epoch 228/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1151 - mse: 26.1151 - mae: 3.5008\n",
            "Epoch 229/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1638 - mse: 25.1638 - mae: 3.4417\n",
            "Epoch 230/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0425 - mse: 26.0425 - mae: 3.5213\n",
            "Epoch 231/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5503 - mse: 25.5503 - mae: 3.5419\n",
            "Epoch 232/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0819 - mse: 26.0819 - mae: 3.4530\n",
            "Epoch 233/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5897 - mse: 25.5897 - mae: 3.4905\n",
            "Epoch 234/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.3464 - mse: 25.3464 - mae: 3.4890\n",
            "Epoch 235/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8408 - mse: 25.8408 - mae: 3.5121\n",
            "Epoch 236/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3495 - mse: 25.3495 - mae: 3.3983\n",
            "Epoch 237/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.1741 - mse: 26.1741 - mae: 3.5368\n",
            "Epoch 238/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2080 - mse: 25.2080 - mae: 3.4386\n",
            "Epoch 239/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9934 - mse: 25.9934 - mae: 3.4366\n",
            "Epoch 240/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4807 - mse: 25.4807 - mae: 3.5117\n",
            "Epoch 241/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6534 - mse: 25.6534 - mae: 3.4881\n",
            "Epoch 242/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1904 - mse: 25.1904 - mae: 3.4706\n",
            "Epoch 243/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3261 - mse: 26.3261 - mae: 3.5835\n",
            "Epoch 244/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6183 - mse: 25.6183 - mae: 3.5278\n",
            "Epoch 245/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0342 - mse: 26.0342 - mae: 3.4768\n",
            "Epoch 246/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3328 - mse: 25.3328 - mae: 3.4933\n",
            "Epoch 247/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0775 - mse: 26.0775 - mae: 3.4756\n",
            "Epoch 248/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9082 - mse: 25.9082 - mae: 3.4588\n",
            "Epoch 249/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3212 - mse: 25.3212 - mae: 3.5154\n",
            "Epoch 250/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7190 - mse: 25.7190 - mae: 3.4808\n",
            "Epoch 251/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4264 - mse: 25.4264 - mae: 3.4969\n",
            "Epoch 252/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7366 - mse: 25.7366 - mae: 3.4940\n",
            "Epoch 253/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.4601 - mse: 26.4601 - mae: 3.4253\n",
            "Epoch 254/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0048 - mse: 26.0048 - mae: 3.4911\n",
            "Epoch 255/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4798 - mse: 25.4798 - mae: 3.3839\n",
            "Epoch 256/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7843 - mse: 25.7843 - mae: 3.5352\n",
            "Epoch 257/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1086 - mse: 26.1086 - mae: 3.4223\n",
            "Epoch 258/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0273 - mse: 26.0273 - mae: 3.4965\n",
            "Epoch 259/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9800 - mse: 25.9800 - mae: 3.4444\n",
            "Epoch 260/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.3621 - mse: 26.3621 - mae: 3.5132\n",
            "Epoch 261/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8518 - mse: 25.8518 - mae: 3.5262\n",
            "Epoch 262/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1182 - mse: 25.1182 - mae: 3.4006\n",
            "Epoch 263/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3165 - mse: 25.3165 - mae: 3.4147\n",
            "Epoch 264/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5804 - mse: 25.5804 - mae: 3.4219\n",
            "Epoch 265/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.3218 - mse: 25.3218 - mae: 3.4535\n",
            "Epoch 266/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.9226 - mse: 25.9226 - mae: 3.4722\n",
            "Epoch 267/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5510 - mse: 25.5510 - mae: 3.4675\n",
            "Epoch 268/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8035 - mse: 25.8035 - mae: 3.4933\n",
            "Epoch 269/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0563 - mse: 26.0563 - mae: 3.4647\n",
            "Epoch 270/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5393 - mse: 25.5393 - mae: 3.4828\n",
            "Epoch 271/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3311 - mse: 25.3311 - mae: 3.4822\n",
            "Epoch 272/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5572 - mse: 25.5572 - mae: 3.4421\n",
            "Epoch 273/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 26.0478 - mse: 26.0478 - mae: 3.4942\n",
            "Epoch 274/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2624 - mse: 26.2624 - mae: 3.5335\n",
            "Epoch 275/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3602 - mse: 25.3602 - mae: 3.4880\n",
            "Epoch 276/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8047 - mse: 25.8047 - mae: 3.4627\n",
            "Epoch 277/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8093 - mse: 25.8093 - mae: 3.4797\n",
            "Epoch 278/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8243 - mse: 25.8243 - mae: 3.5327\n",
            "Epoch 279/500\n",
            "68/68 [==============================] - 0s 2ms/step - loss: 25.6945 - mse: 25.6945 - mae: 3.4713\n",
            "Epoch 280/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5943 - mse: 25.5943 - mae: 3.5026\n",
            "Epoch 281/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1063 - mse: 25.1063 - mae: 3.4571\n",
            "Epoch 282/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8008 - mse: 25.8008 - mae: 3.5108\n",
            "Epoch 283/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4926 - mse: 25.4926 - mae: 3.4448\n",
            "Epoch 284/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4928 - mse: 25.4928 - mae: 3.4428\n",
            "Epoch 285/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0954 - mse: 26.0954 - mae: 3.5225\n",
            "Epoch 286/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1775 - mse: 26.1775 - mae: 3.5108\n",
            "Epoch 287/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4712 - mse: 25.4712 - mae: 3.4770\n",
            "Epoch 288/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4944 - mse: 25.4944 - mae: 3.4967\n",
            "Epoch 289/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8885 - mse: 25.8885 - mae: 3.4997\n",
            "Epoch 290/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4435 - mse: 25.4435 - mae: 3.4326\n",
            "Epoch 291/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1725 - mse: 25.1725 - mae: 3.4922\n",
            "Epoch 292/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7105 - mse: 25.7105 - mae: 3.4291\n",
            "Epoch 293/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5925 - mse: 25.5925 - mae: 3.4758\n",
            "Epoch 294/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4995 - mse: 25.4995 - mae: 3.4658\n",
            "Epoch 295/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5484 - mse: 25.5484 - mae: 3.4630\n",
            "Epoch 296/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7552 - mse: 25.7552 - mae: 3.5366\n",
            "Epoch 297/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2672 - mse: 26.2672 - mae: 3.4542\n",
            "Epoch 298/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5202 - mse: 25.5202 - mae: 3.4810\n",
            "Epoch 299/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7517 - mse: 25.7517 - mae: 3.4712\n",
            "Epoch 300/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7592 - mse: 25.7592 - mae: 3.4787\n",
            "Epoch 301/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1232 - mse: 26.1232 - mae: 3.5282\n",
            "Epoch 302/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1216 - mse: 26.1216 - mae: 3.5144\n",
            "Epoch 303/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1032 - mse: 26.1032 - mae: 3.4961\n",
            "Epoch 304/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7776 - mse: 25.7776 - mae: 3.4153\n",
            "Epoch 305/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1237 - mse: 26.1237 - mae: 3.5432\n",
            "Epoch 306/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5058 - mse: 25.5058 - mae: 3.4475\n",
            "Epoch 307/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9208 - mse: 25.9208 - mae: 3.5102\n",
            "Epoch 308/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7217 - mse: 25.7217 - mae: 3.4521\n",
            "Epoch 309/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5949 - mse: 25.5949 - mae: 3.4536\n",
            "Epoch 310/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3935 - mse: 25.3935 - mae: 3.4770\n",
            "Epoch 311/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6534 - mse: 25.6534 - mae: 3.4374\n",
            "Epoch 312/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8228 - mse: 25.8228 - mae: 3.5007\n",
            "Epoch 313/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.9491 - mse: 24.9491 - mae: 3.4648\n",
            "Epoch 314/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7653 - mse: 25.7653 - mae: 3.4457\n",
            "Epoch 315/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6908 - mse: 25.6908 - mae: 3.5074\n",
            "Epoch 316/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5667 - mse: 25.5667 - mae: 3.4755\n",
            "Epoch 317/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6399 - mse: 25.6399 - mae: 3.5116\n",
            "Epoch 318/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6033 - mse: 25.6033 - mae: 3.4832\n",
            "Epoch 319/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9443 - mse: 25.9443 - mae: 3.5089\n",
            "Epoch 320/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9226 - mse: 25.9226 - mae: 3.4540\n",
            "Epoch 321/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8003 - mse: 25.8003 - mae: 3.4981\n",
            "Epoch 322/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7843 - mse: 25.7843 - mae: 3.4600\n",
            "Epoch 323/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6980 - mse: 25.6980 - mae: 3.4615\n",
            "Epoch 324/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1149 - mse: 26.1149 - mae: 3.4785\n",
            "Epoch 325/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4158 - mse: 25.4158 - mae: 3.4420\n",
            "Epoch 326/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5087 - mse: 25.5087 - mae: 3.5426\n",
            "Epoch 327/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5207 - mse: 25.5207 - mae: 3.5194\n",
            "Epoch 328/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6717 - mse: 25.6717 - mae: 3.4718\n",
            "Epoch 329/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5726 - mse: 25.5726 - mae: 3.5001\n",
            "Epoch 330/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7791 - mse: 25.7791 - mae: 3.4470\n",
            "Epoch 331/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2019 - mse: 26.2019 - mae: 3.5024\n",
            "Epoch 332/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1154 - mse: 26.1154 - mae: 3.4808\n",
            "Epoch 333/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.6799 - mse: 24.6799 - mae: 3.4157\n",
            "Epoch 334/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.9829 - mse: 26.9829 - mae: 3.6648\n",
            "Epoch 335/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9694 - mse: 25.9694 - mae: 3.4893\n",
            "Epoch 336/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8699 - mse: 25.8699 - mae: 3.4869\n",
            "Epoch 337/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4948 - mse: 25.4948 - mae: 3.4083\n",
            "Epoch 338/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3682 - mse: 25.3682 - mae: 3.4427\n",
            "Epoch 339/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7016 - mse: 25.7016 - mae: 3.4739\n",
            "Epoch 340/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5204 - mse: 25.5204 - mae: 3.4292\n",
            "Epoch 341/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9294 - mse: 25.9294 - mae: 3.4503\n",
            "Epoch 342/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9076 - mse: 25.9076 - mae: 3.4613\n",
            "Epoch 343/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2973 - mse: 26.2973 - mae: 3.4922\n",
            "Epoch 344/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3419 - mse: 25.3419 - mae: 3.4541\n",
            "Epoch 345/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7396 - mse: 25.7396 - mae: 3.4706\n",
            "Epoch 346/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.8956 - mse: 24.8956 - mae: 3.5707\n",
            "Epoch 347/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8436 - mse: 25.8436 - mae: 3.4723\n",
            "Epoch 348/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1003 - mse: 26.1003 - mae: 3.4513\n",
            "Epoch 349/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4319 - mse: 25.4319 - mae: 3.4294\n",
            "Epoch 350/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.0113 - mse: 25.0113 - mae: 3.4982\n",
            "Epoch 351/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8391 - mse: 25.8391 - mae: 3.5088\n",
            "Epoch 352/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3205 - mse: 25.3205 - mae: 3.4915\n",
            "Epoch 353/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5955 - mse: 25.5955 - mae: 3.5212\n",
            "Epoch 354/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6465 - mse: 25.6465 - mae: 3.4859\n",
            "Epoch 355/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9675 - mse: 25.9675 - mae: 3.4853\n",
            "Epoch 356/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8185 - mse: 25.8185 - mae: 3.4538\n",
            "Epoch 357/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3920 - mse: 25.3920 - mae: 3.4087\n",
            "Epoch 358/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4773 - mse: 25.4773 - mae: 3.4626\n",
            "Epoch 359/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8740 - mse: 25.8740 - mae: 3.4545\n",
            "Epoch 360/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1602 - mse: 26.1602 - mae: 3.4317\n",
            "Epoch 361/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5279 - mse: 25.5279 - mae: 3.4419\n",
            "Epoch 362/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3681 - mse: 25.3681 - mae: 3.4565\n",
            "Epoch 363/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0990 - mse: 26.0990 - mae: 3.5386\n",
            "Epoch 364/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.0674 - mse: 25.0674 - mae: 3.4692\n",
            "Epoch 365/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8809 - mse: 25.8809 - mae: 3.5982\n",
            "Epoch 366/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2510 - mse: 25.2510 - mae: 3.5165\n",
            "Epoch 367/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8802 - mse: 25.8802 - mae: 3.4615\n",
            "Epoch 368/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8766 - mse: 25.8766 - mae: 3.4998\n",
            "Epoch 369/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1640 - mse: 25.1640 - mae: 3.4091\n",
            "Epoch 370/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3192 - mse: 26.3192 - mae: 3.5190\n",
            "Epoch 371/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9258 - mse: 25.9258 - mae: 3.4958\n",
            "Epoch 372/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2419 - mse: 25.2419 - mae: 3.4643\n",
            "Epoch 373/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7086 - mse: 25.7086 - mae: 3.5469\n",
            "Epoch 374/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2414 - mse: 26.2414 - mae: 3.4939\n",
            "Epoch 375/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0679 - mse: 26.0679 - mae: 3.4619\n",
            "Epoch 376/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5152 - mse: 25.5152 - mae: 3.5326\n",
            "Epoch 377/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5626 - mse: 25.5626 - mae: 3.4869\n",
            "Epoch 378/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8876 - mse: 25.8876 - mae: 3.4666\n",
            "Epoch 379/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2988 - mse: 26.2988 - mae: 3.4532\n",
            "Epoch 380/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4094 - mse: 25.4094 - mae: 3.4743\n",
            "Epoch 381/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7187 - mse: 25.7187 - mae: 3.5373\n",
            "Epoch 382/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6543 - mse: 25.6543 - mae: 3.5564\n",
            "Epoch 383/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0740 - mse: 26.0740 - mae: 3.5462\n",
            "Epoch 384/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4635 - mse: 25.4635 - mae: 3.4521\n",
            "Epoch 385/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7160 - mse: 25.7160 - mae: 3.5048\n",
            "Epoch 386/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6503 - mse: 25.6503 - mae: 3.4715\n",
            "Epoch 387/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1167 - mse: 26.1167 - mae: 3.4552\n",
            "Epoch 388/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.0472 - mse: 25.0472 - mae: 3.4649\n",
            "Epoch 389/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6101 - mse: 25.6101 - mae: 3.4482\n",
            "Epoch 390/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9495 - mse: 25.9495 - mae: 3.4836\n",
            "Epoch 391/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6002 - mse: 25.6002 - mae: 3.4420\n",
            "Epoch 392/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7264 - mse: 25.7264 - mae: 3.4537\n",
            "Epoch 393/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6277 - mse: 25.6277 - mae: 3.4763\n",
            "Epoch 394/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7264 - mse: 25.7264 - mae: 3.4814\n",
            "Epoch 395/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6065 - mse: 25.6065 - mae: 3.5101\n",
            "Epoch 396/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9876 - mse: 25.9876 - mae: 3.4360\n",
            "Epoch 397/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5914 - mse: 25.5914 - mae: 3.5350\n",
            "Epoch 398/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5429 - mse: 25.5429 - mae: 3.4938\n",
            "Epoch 399/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7371 - mse: 25.7371 - mae: 3.4097\n",
            "Epoch 400/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2165 - mse: 26.2165 - mae: 3.5101\n",
            "Epoch 401/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0108 - mse: 26.0108 - mae: 3.4142\n",
            "Epoch 402/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5322 - mse: 25.5322 - mae: 3.4565\n",
            "Epoch 403/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9560 - mse: 25.9560 - mae: 3.4765\n",
            "Epoch 404/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9138 - mse: 25.9138 - mae: 3.4949\n",
            "Epoch 405/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2090 - mse: 25.2090 - mae: 3.4520\n",
            "Epoch 406/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4528 - mse: 25.4528 - mae: 3.4903\n",
            "Epoch 407/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8424 - mse: 25.8424 - mae: 3.4699\n",
            "Epoch 408/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7283 - mse: 25.7283 - mae: 3.4181\n",
            "Epoch 409/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3358 - mse: 25.3358 - mae: 3.4592\n",
            "Epoch 410/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6942 - mse: 25.6942 - mae: 3.4379\n",
            "Epoch 411/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2772 - mse: 25.2772 - mae: 3.4897\n",
            "Epoch 412/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1262 - mse: 26.1262 - mae: 3.4766\n",
            "Epoch 413/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8713 - mse: 25.8713 - mae: 3.4886\n",
            "Epoch 414/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3867 - mse: 25.3867 - mae: 3.4530\n",
            "Epoch 415/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.2268 - mse: 26.2268 - mae: 3.5014\n",
            "Epoch 416/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3827 - mse: 25.3827 - mae: 3.4745\n",
            "Epoch 417/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0369 - mse: 26.0369 - mae: 3.4996\n",
            "Epoch 418/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6349 - mse: 25.6349 - mae: 3.5103\n",
            "Epoch 419/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8143 - mse: 25.8143 - mae: 3.4606\n",
            "Epoch 420/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1216 - mse: 26.1216 - mae: 3.5276\n",
            "Epoch 421/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9812 - mse: 25.9812 - mae: 3.5146\n",
            "Epoch 422/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4495 - mse: 25.4495 - mae: 3.4459\n",
            "Epoch 423/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.3663 - mse: 26.3663 - mae: 3.6206\n",
            "Epoch 424/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3590 - mse: 25.3590 - mae: 3.4584\n",
            "Epoch 425/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7956 - mse: 25.7956 - mae: 3.4415\n",
            "Epoch 426/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7088 - mse: 25.7088 - mae: 3.4588\n",
            "Epoch 427/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9578 - mse: 25.9578 - mae: 3.4619\n",
            "Epoch 428/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8100 - mse: 25.8100 - mae: 3.5445\n",
            "Epoch 429/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9513 - mse: 25.9513 - mae: 3.4407\n",
            "Epoch 430/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6352 - mse: 25.6352 - mae: 3.3691\n",
            "Epoch 431/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9488 - mse: 25.9488 - mae: 3.4954\n",
            "Epoch 432/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9560 - mse: 25.9560 - mae: 3.4697\n",
            "Epoch 433/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9014 - mse: 25.9014 - mae: 3.5146\n",
            "Epoch 434/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5826 - mse: 25.5826 - mae: 3.4753\n",
            "Epoch 435/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8180 - mse: 25.8180 - mae: 3.4822\n",
            "Epoch 436/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5236 - mse: 25.5236 - mae: 3.4610\n",
            "Epoch 437/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.7376 - mse: 25.7376 - mae: 3.5105\n",
            "Epoch 438/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1295 - mse: 25.1295 - mae: 3.4189\n",
            "Epoch 439/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8867 - mse: 25.8867 - mae: 3.4714\n",
            "Epoch 440/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.0536 - mse: 25.0536 - mae: 3.4259\n",
            "Epoch 441/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6122 - mse: 25.6122 - mae: 3.4658\n",
            "Epoch 442/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8264 - mse: 25.8264 - mae: 3.4750\n",
            "Epoch 443/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8510 - mse: 25.8510 - mae: 3.4495\n",
            "Epoch 444/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0399 - mse: 26.0399 - mae: 3.4758\n",
            "Epoch 445/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6164 - mse: 25.6164 - mae: 3.4660\n",
            "Epoch 446/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3415 - mse: 25.3415 - mae: 3.4014\n",
            "Epoch 447/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3397 - mse: 25.3397 - mae: 3.3964\n",
            "Epoch 448/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8506 - mse: 25.8506 - mae: 3.5100\n",
            "Epoch 449/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3085 - mse: 25.3085 - mae: 3.4344\n",
            "Epoch 450/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9527 - mse: 25.9527 - mae: 3.4302\n",
            "Epoch 451/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4244 - mse: 25.4244 - mae: 3.4767\n",
            "Epoch 452/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.9803 - mse: 24.9803 - mae: 3.4476\n",
            "Epoch 453/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8177 - mse: 25.8177 - mae: 3.5211\n",
            "Epoch 454/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4375 - mse: 25.4375 - mae: 3.4916\n",
            "Epoch 455/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8966 - mse: 25.8966 - mae: 3.4610\n",
            "Epoch 456/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1499 - mse: 26.1499 - mae: 3.4939\n",
            "Epoch 457/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4673 - mse: 25.4673 - mae: 3.4909\n",
            "Epoch 458/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8419 - mse: 25.8419 - mae: 3.4529\n",
            "Epoch 459/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4264 - mse: 25.4264 - mae: 3.4940\n",
            "Epoch 460/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3226 - mse: 25.3226 - mae: 3.4962\n",
            "Epoch 461/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4750 - mse: 25.4750 - mae: 3.4482\n",
            "Epoch 462/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5025 - mse: 25.5025 - mae: 3.4876\n",
            "Epoch 463/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9386 - mse: 25.9386 - mae: 3.5138\n",
            "Epoch 464/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6713 - mse: 25.6713 - mae: 3.4576\n",
            "Epoch 465/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5606 - mse: 25.5606 - mae: 3.4540\n",
            "Epoch 466/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2996 - mse: 25.2996 - mae: 3.5093\n",
            "Epoch 467/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6727 - mse: 25.6727 - mae: 3.4955\n",
            "Epoch 468/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5252 - mse: 25.5252 - mae: 3.4334\n",
            "Epoch 469/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6548 - mse: 25.6548 - mae: 3.5080\n",
            "Epoch 470/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.8635 - mse: 24.8635 - mae: 3.5125\n",
            "Epoch 471/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0684 - mse: 26.0684 - mae: 3.5275\n",
            "Epoch 472/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8812 - mse: 25.8812 - mae: 3.5442\n",
            "Epoch 473/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6036 - mse: 25.6036 - mae: 3.4406\n",
            "Epoch 474/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.2381 - mse: 25.2381 - mae: 3.4968\n",
            "Epoch 475/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.4943 - mse: 25.4943 - mae: 3.4185\n",
            "Epoch 476/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8873 - mse: 25.8873 - mae: 3.4853\n",
            "Epoch 477/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9701 - mse: 25.9701 - mae: 3.5122\n",
            "Epoch 478/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3392 - mse: 25.3392 - mae: 3.4404\n",
            "Epoch 479/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5844 - mse: 25.5844 - mae: 3.4652\n",
            "Epoch 480/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3087 - mse: 25.3087 - mae: 3.4452\n",
            "Epoch 481/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3642 - mse: 25.3642 - mae: 3.4633\n",
            "Epoch 482/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8438 - mse: 25.8438 - mae: 3.4564\n",
            "Epoch 483/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.1973 - mse: 25.1973 - mae: 3.4207\n",
            "Epoch 484/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.8528 - mse: 25.8528 - mae: 3.4499\n",
            "Epoch 485/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6660 - mse: 25.6660 - mae: 3.4907\n",
            "Epoch 486/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 24.7831 - mse: 24.7831 - mae: 3.4953\n",
            "Epoch 487/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3669 - mse: 25.3669 - mae: 3.4473\n",
            "Epoch 488/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5887 - mse: 25.5887 - mae: 3.4761\n",
            "Epoch 489/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1244 - mse: 26.1244 - mae: 3.5265\n",
            "Epoch 490/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.9504 - mse: 25.9504 - mae: 3.5239\n",
            "Epoch 491/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.1662 - mse: 26.1662 - mae: 3.4555\n",
            "Epoch 492/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0701 - mse: 26.0701 - mae: 3.5134\n",
            "Epoch 493/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6644 - mse: 25.6644 - mae: 3.4976\n",
            "Epoch 494/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6576 - mse: 25.6576 - mae: 3.5322\n",
            "Epoch 495/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5406 - mse: 25.5406 - mae: 3.4638\n",
            "Epoch 496/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.6217 - mse: 25.6217 - mae: 3.4996\n",
            "Epoch 497/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 26.0931 - mse: 26.0931 - mae: 3.5360\n",
            "Epoch 498/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5036 - mse: 25.5036 - mae: 3.3936\n",
            "Epoch 499/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.3031 - mse: 25.3031 - mae: 3.5000\n",
            "Epoch 500/500\n",
            "68/68 [==============================] - 0s 3ms/step - loss: 25.5459 - mse: 25.5459 - mae: 3.4522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ef3f822e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ0PZ1hHcMzR"
      },
      "source": [
        "Inference from the given model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbtf1dQgbo_4",
        "outputId": "d4ea0bcc-dabc-46e2-bfcc-59879e6384a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# This is for calculating the loss for test set data\n",
        "model.evaluate(X_test, Y_test, verbose=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 27.5576 - mse: 27.5576 - mae: 3.8968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[27.557592391967773, 27.557592391967773, 3.8967504501342773]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8JzB_ITbqlX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCGfCBQ7c_nz",
        "outputId": "5080794e-37bd-402b-81cd-19442f9ccc2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# To find output using our train model\n",
        "Y_pred = model.predict(X_test)\n",
        "# Comparing predicted with test sample\n",
        "print(Y_test[:5])\n",
        "print(Y_pred[:5,0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7.2 18.8 19.  27.  22.2]\n",
            "[10.148695 20.3457   22.700144 31.388618 25.04748 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw7_PSQ6dJ3Z",
        "outputId": "6278aa79-8bf6-4d1d-9ad1-f397d6e97e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The hyper parameter epoch = 500 \n",
        "# batch size is 5\n",
        "# To find output using our train model\n",
        "Y_pred = model.predict(X_test)\n",
        "# Comparing predicted with test sample\n",
        "print(Y_test[:5])\n",
        "print(Y_pred[:5,0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 7.2 18.8 19.  27.  22.2]\n",
            "[ 7.098922 17.010742 20.300259 28.322706 22.592415]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gPsW75EeMJd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}